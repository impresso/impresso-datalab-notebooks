{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/blob/main/workshop_resources/ws4-embeddings/MultiLingual-updated.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "_A1NlFD3aDeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilingual Embeddings\n",
        "\n",
        "This notebook provides basic functionality for studying embedding across languages. Based on a corpus of medical ads we aim to explor cross-lingual connection using different types of visualisations\n",
        "- a scatter plot of embedding using dimensionality reduction (UMAP)\n",
        "- a heatmap that compares all the embeddings and highlight similar items\n",
        "\n",
        "**Important**\n",
        "\n",
        "The first part of this notebook shows how to retrieve and prepare data for analysis (\"Data preparation\"). However, you can skip this part and go directly to \"Cross-lingual search\" and the following section, where you can download the processed data."
      ],
      "metadata": {
        "id": "6RYEarZhDpWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Impresso library"
      ],
      "metadata": {
        "id": "tpLCNxwNECBY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YglrIFzDKqjp"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq git+https://github.com/impresso/impresso-py.git@embeddings-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restart the kernel just in case...\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "e4beXbO1K4yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "ulA-zkpgEGp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "QJCRr8YVOH2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions for embedding text and retrieving vectors\n",
        "import time\n",
        "import base64\n",
        "import struct\n",
        "\n",
        "def embed_text(text: str, target: str):\n",
        "  \"\"\"\n",
        "  Convert text to embedding, return None in case of an error\n",
        "  \"\"\"\n",
        "  #time.sleep(.1)\n",
        "  try:\n",
        "    return impresso_session.tools.embed_text(text, target)\n",
        "  except Exception as e:\n",
        "    return None\n",
        "\n",
        "\n",
        "def convert_embedding(embedding: np.float32):\n",
        "  \"\"\"\n",
        "  Convert base64 string to a float array\n",
        "  \"\"\"\n",
        "  if not embedding:\n",
        "    return None\n",
        "\n",
        "  _, arr = embedding.split(':')\n",
        "  arr = base64.b64decode(arr)\n",
        "  outof_corpus_emb = [struct.unpack('f', arr[i:i+4])[0] for i in range(0, len(arr), 4)]\n",
        "  return outof_corpus_emb\n",
        "\n",
        "# get the article embeddings from the API\n",
        "\n",
        "def get_embedding_by_uid(uid):\n",
        "  #time.sleep(.1)\n",
        "  try:\n",
        "    return impresso_session.content_items.get_embeddings(uid)[0]\n",
        "  except Exception as e:\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_embedding_from_api(row ,text_col, target='text'):\n",
        "  \"\"\"first check if embedding already exists\n",
        "  other create embedding\n",
        "  \"\"\"\n",
        "  embedding = get_embedding_by_uid(row['uid'])\n",
        "  if not embedding:\n",
        "    embedding = embed_text(row[text_col], target)\n",
        "  return convert_embedding(embedding)\n"
      ],
      "metadata": {
        "id": "I1bcn9M5Gct4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the Impresso client"
      ],
      "metadata": {
        "id": "ZKNLj8u_EIxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from impresso import connect\n",
        "\n",
        "impresso_session = connect('https://dev.impresso-project.ch/public-api/v1')"
      ],
      "metadata": {
        "id": "zJO_ddQjK7mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "\n",
        "Below we provide a link to the processed data, so feel free skip to this part."
      ],
      "metadata": {
        "id": "ANEiI6KCERK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and unzip data"
      ],
      "metadata": {
        "id": "4dbDLyCFEZPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1qUyd9iKdl7eX3Kg0H8lbhbtXPudA3gGD"
      ],
      "metadata": {
        "id": "oE2kVZJIFwte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the data for the general query\n",
        "!unzip -o impresso_WS4data.zip -d data"
      ],
      "metadata": {
        "id": "p20kiZNRLFsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = '/content/data/impresso_WS4data/webapp_malariaPaludismeOR.csv'\n",
        "df = pd.read_csv(CSV_PATH, sep=';',skiprows=4)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "BasPxfSHOCHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "EcZg9oGCORNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's inspect the distribution of the language codes."
      ],
      "metadata": {
        "id": "5TKzDM2vGAoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.languageCode.value_counts()"
      ],
      "metadata": {
        "id": "52V4iwwlOafV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now, we sample a subset of evenly divided over both languages in our dataset."
      ],
      "metadata": {
        "id": "fE5G420RGGep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = pd.concat([df[df.languageCode=='de'].sample(500,random_state=42),\n",
        "                       df[df.languageCode=='fr'].sample(500,random_state=42)],\n",
        "                      ignore_index=True)"
      ],
      "metadata": {
        "id": "a5jC1IAGPZBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample.shape"
      ],
      "metadata": {
        "id": "aTVXWrDXQNiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-lingual search with the Impresso API\n",
        "\n",
        "The example below demonstrates the Impresso API for searching items across languages. We use an embedded German text to query the the vector space of French items."
      ],
      "metadata": {
        "id": "sHZN88bkQ18H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define query and target language\n",
        "query_lang = 'de'\n",
        "target_lang = 'fr'"
      ],
      "metadata": {
        "id": "p9SZ6SFcTc3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the uid of an article\n",
        "row = df[df.languageCode==query_lang].sample(1)#['uid'].values[0]\n",
        "text = str(row.transcript.values[0])\n",
        "text"
      ],
      "metadata": {
        "id": "H-y6i296UeyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve embedding for text\n",
        "embedding = embed_text(text, 'text')\n",
        "print(embedding)"
      ],
      "metadata": {
        "id": "XuMk_lh3Chjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use embedding to query in French\n",
        "results = impresso_session.search.find(\n",
        "  language = target_lang,\n",
        "  embedding=embedding,\n",
        "  limit=4\n",
        ")"
      ],
      "metadata": {
        "id": "bImrYHkMQxhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "Ul20Mr4OXd-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embed text with the Impresso API\n",
        "\n",
        "The code below showns how to retrieve embeddings. It combines texts that were already embedded (and can just be retrieved from the database) as well as documents without a pre-existing embedding, for which we need to use `embed_text' functionality."
      ],
      "metadata": {
        "id": "SHGqYKUvXoqa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lZmd-fasL8qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample.columns"
      ],
      "metadata": {
        "id": "scTl7z7JVXHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retrieve or create embeddings using the Impresso API."
      ],
      "metadata": {
        "id": "McdtHedhHM_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas()\n",
        "df_sample['transcript_embedding']  = df_sample.progress_apply(get_embedding_from_api, text_col='transcript', axis=1)"
      ],
      "metadata": {
        "id": "3zG5O20FXr9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "impresso_session.content_items.get_embeddings('BNN-1887-01-16-a-i0004')"
      ],
      "metadata": {
        "id": "huHbBye2YEce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save output\n",
        "df_sample.to_json('df_sample-embedded.json')"
      ],
      "metadata": {
        "id": "2RsmTm2QYj6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Embeddings\n",
        "\n",
        "## UMAP\n",
        "\n",
        "\n",
        "After creating embeddings we can explore the vector space visually. In this notebook we first visualise embeddings on a 2d plane using UMAP and use plotly to inspect the resulting space as an interactive scatterplot."
      ],
      "metadata": {
        "id": "9AnbX0KNY4RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qqq install seaborn plotly umap-learn"
      ],
      "metadata": {
        "id": "y6MypBnwYhet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1w_PnhWl55qmIHdMo1NKDx1pXOBkmIv2W"
      ],
      "metadata": {
        "id": "elYKn1jZKOGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we run the code for dimensionality reduction. You might get the following error:\n",
        "\n",
        "```AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'```\n",
        "\n",
        "Please ignore these errors, they won't break anything."
      ],
      "metadata": {
        "id": "HLduke64EU8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DIMENSIONALITY REDUCTION ---\n",
        "from umap import UMAP\n",
        "print(\"Reducing to 2D with UMAP...\")\n",
        "reducer = UMAP(\n",
        "    n_neighbors=15,\n",
        "    min_dist=0.1,\n",
        "    metric=\"cosine\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "EMBEDDING = 'transcript_embedding' # 'title_embedding' | 'article_embedding'\n",
        "\n",
        "df_sample = pd.read_json('df_sample-embedded.json')\n",
        "\n",
        "df_sample = df_sample[~df_sample[EMBEDDING].isnull()]\n",
        "\n",
        "embeddings = list(df_sample[EMBEDDING])\n",
        "embeddings_2d = reducer.fit_transform(embeddings)\n",
        "\n",
        "df_sample[\"x\"] = embeddings_2d[:, 0]\n",
        "df_sample[\"y\"] = embeddings_2d[:, 1]"
      ],
      "metadata": {
        "id": "aNKAbSb1Y_W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean_text(text, max_len=100):\n",
        "    \"\"\"Truncate text and replace newlines for nicer tooltips\"\"\"\n",
        "    text = str(text).replace(\"\\n\", \" \")\n",
        "    return text[:max_len] + (\"...\" if len(text) > max_len else \"\")\n",
        "\n",
        "df_sample[\"hover_text\"] = df_sample.transcript.apply(clean_text)\n"
      ],
      "metadata": {
        "id": "Tcd9yiwQZdmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalized, size = individual, colour = servants\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter(df_sample,\n",
        "                 x=\"x\",\n",
        "                 size='transcriptLength',\n",
        "                 y=\"y\",\n",
        "                 color=\"languageCode\",\n",
        "                 hover_data=['hover_text'],\n",
        "                 width=1000, height=1000)\n",
        "fig.update_layout(showlegend=False)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vsoxSe0hZitB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlWpSxgcaPY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heatmap\n",
        "\n",
        "We compare the similarity of articles across languages and sample the most similar pairs. First we create compare the similarity of each German vectors to each French vector.\n",
        "\n",
        "Then we sample the most similar cross-lingual pairs and inspect their content"
      ],
      "metadata": {
        "id": "2DYadfBzaRZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_de = list(df_sample[df_sample.languageCode=='de']['transcript_embedding'])\n",
        "embeddings_fr = list(df_sample[df_sample.languageCode=='de']['transcript_embedding'])"
      ],
      "metadata": {
        "id": "shGJzh6RaBKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a similarity matrix, comparing all vector in German to French vectors and visualise the result as a heatmap."
      ],
      "metadata": {
        "id": "jhvx0ugGK8p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(embeddings_de, embeddings_fr)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(similarity_matrix, cmap=\"viridis\", annot=False)\n",
        "plt.title(\"Cosine Similarity Heatmap: X vs Y\")\n",
        "plt.xlabel(\"Y Embeddings\")\n",
        "plt.ylabel(\"X Embeddings\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Lv5OggWPa3-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_de = df_sample[df_sample.languageCode=='de'].reset_index(drop=True)\n",
        "df_fr = df_sample[df_sample.languageCode=='fr'].reset_index(drop=True)\n",
        "len(df_de), len(embeddings_de)"
      ],
      "metadata": {
        "id": "TqA-4R1ecquA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample similar pairs ignoring those on diagonal\n",
        "similar = [(int(i),int(j)) for i,j in list(zip(*np.where(similarity_matrix > 0.9))) if i != j]"
      ],
      "metadata": {
        "id": "H8EjCkyjb2Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar"
      ],
      "metadata": {
        "id": "ffSUxOMMcMjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i,j = similar[0]\n"
      ],
      "metadata": {
        "id": "hT06iEcTcxIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_de.iloc[i].transcript"
      ],
      "metadata": {
        "id": "p4fBMVSuf9ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr.iloc[j].transcript"
      ],
      "metadata": {
        "id": "Ov1Xx_25d3tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query\n",
        "\n",
        "\n",
        "In this part, we index the embedded vectors with FAISS. And use the vectors database to search for German articles using the French transcripts. This can be easily reversed."
      ],
      "metadata": {
        "id": "l9NUpwSeevzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qqq install faiss-cpu"
      ],
      "metadata": {
        "id": "2Sd093xTgdX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- VECTOR STORE (FAISS) ---\n",
        "# save index\n",
        "import faiss\n",
        "\n",
        "\n",
        "\n",
        "df_sample = pd.read_json('df_sample-embedded.json')\n",
        "\n",
        "EMBEDDING = 'transcript_embedding'\n",
        "\n",
        "print(df_sample.languageCode.value_counts())\n",
        "query_lang = 'de'\n",
        "target_lang = 'fr'\n",
        "df_q = df_sample[(~df_sample[EMBEDDING].isnull()) & (df_sample.languageCode==query_lang)]\n",
        "df_t = df_sample[(~df_sample[EMBEDDING].isnull()) & (df_sample.languageCode==target_lang)]\n",
        "\n",
        "embeddings_q = list(df_q[EMBEDDING])\n",
        "\n",
        "VECTOR_DB_PATH = f\"vector_db_{query_lang}.faiss\"\n",
        "embeddings = np.array(list(df_q[EMBEDDING]), dtype=\"float32\")\n",
        "\n",
        "\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(embeddings)\n",
        "faiss.write_index(index, VECTOR_DB_PATH)\n",
        "print(f\"Vector DB saved to {VECTOR_DB_PATH}\")\n"
      ],
      "metadata": {
        "id": "zNXnvS-qd_5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query = df_t.iloc[0].transcript\n",
        "print(query)\n",
        "q_emb = convert_embedding(embed_text(query,'text'))\n",
        "\n",
        "D, I = index.search(np.array([q_emb], dtype=\"float32\"), k=5)\n",
        "print(\"Top 5 most similar articles:\")\n",
        "print(df_q.iloc[I[0]])"
      ],
      "metadata": {
        "id": "BekRZyfWgm2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fin."
      ],
      "metadata": {
        "id": "WUKVtwNdLd9J"
      }
    }
  ]
}
