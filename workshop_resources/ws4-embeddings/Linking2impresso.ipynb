{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/blob/main/workshop_resources/ws4-embeddings/Linking2impresso.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "HR4045u-NGsZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8rfa2EVehqV"
      },
      "source": [
        "# ‚öìÔ∏è Linking2Impresso: Connecting your Data with Impresso\n",
        "\n",
        "This notebook demonstrates how to \"dock\" an external text collection (bonus: image collection) into the Impresso historical media archive using semantic embeddings. By transforming textual data into high-dimensional vector representations, we can measure conceptual similarity between new materials and the vast Impresso corpus. The workflow illustrates the full pipeline: from **preparing a small example collection**, through **embedding and semantic search via the Impresso API**, to **exploring connections through an interactive network visualization**. The resulting graph allows us to quickly see how our own texts resonate with historical documents, opening pathways for contextualization, cross-referencing, and discovery across linguistic and temporal boundaries.\n",
        "\n",
        "In summary, we are going to:\n",
        "1. Load a custom text collection  \n",
        "2. Compute embeddings using Impresso‚Äôs model  \n",
        "3. Search for similar content in the Impresso archive  \n",
        "4. Visualize the matches as an interactive bipartite graph\n",
        "\n",
        "*Author of this notebook: Juri Opitz. **¬©Impresso***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-xPtRYr5c7A"
      },
      "source": [
        "## Installing necessities\n",
        "\n",
        "We install the Impresso python library as well as some tools for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v7LXx1ypfTwA"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/impresso/impresso-py.git@embeddings-search\n",
        "!pip install pyvis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9U3Xksq40u0"
      },
      "source": [
        "## Input Data: Our Example Collections\n",
        "\n",
        "We are using two example collections here, one of French texts and one of English text.\n",
        "\n",
        "Feel free to replace the example collections with any of your texts of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zef4MfukYV2_"
      },
      "source": [
        "### Example Collection I: French Assembly Notes\n",
        "\n",
        "This is an example collection provided by Martin Grandjean.\n",
        "\n",
        "It is **French texts**, so we do not use this here by default. But leave it for further experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP0JpM8Yc-Jc"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "Collectionlink=\"https://gist.githubusercontent.com/flipz357/e22f1f9df1b263d29927ec21440daeab/raw/199869d9ffce9b4121f7a97f00dd57eec4c8e763/gistfile1.txt\"\n",
        "wget $Collectionlink -O collection.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW0qNvsyfLZv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "with open(\"collection.md\", \"r\") as f:\n",
        "    collection = f.read()\n",
        "parts, titles = re.split(\"^#.*$\", collection, flags=re.MULTILINE), [\"notitle\"] + re.findall(\"^#.*$\", collection, flags=re.MULTILINE)\n",
        "parts = [part.replace(\"\\n\", \" \")[:200] for part in parts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s9iJQTKY5DV"
      },
      "source": [
        "### Example Collection II: Geneva Convention Pieces\n",
        "\n",
        "This is an example collection of **English Text**, and we thus use it as the basis for our data. It is fairly short and simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feAYxnBOiGna"
      },
      "outputs": [],
      "source": [
        "parts = [\"Persons in the hands of the enemy are entitled at all times to respect for their life and for their physical and mental integrity.\",\n",
        "         \"Under the first and second Geneva Conventions of 1949, the belligerents must protect the sick, wounded and shipwrecked as well as medical personnel, ambulances and hospitals. All persons protected under these conventions must be given shelter and cared for by the party to the conflict that holds power over them.\",\n",
        "         \"The third Geneva Convention contains detailed rules on the treatment of prisoners of war.\",\n",
        "         \"The fourth Geneva Convention protects civilians in the hands of the enemy, whether in their own or in occupied territory.\",\n",
        "         \"The first Additional Protocol of 1977 supplements the rules applying to international armed conflicts contained in the four Geneva Conventions. It imposes restrictions on the conduct of hostilities; for example, it prohibits attacks against civilians and civilian objects and restricts the means and methods of warfare\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq9yqBmjZ820"
      },
      "source": [
        "## Intitialize an impresso session\n",
        "\n",
        "We connect with the Impresso API üî•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjMtK_vOj7U_"
      },
      "outputs": [],
      "source": [
        "from impresso import connect\n",
        "\n",
        "impresso_session = connect('https://dev.impresso-project.ch/public-api/v1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muT7wHa0aCHf"
      },
      "source": [
        "## Linking! üîó"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr8JWStjaGrJ"
      },
      "source": [
        "### Use Impresso embedding model for embedding your collection\n",
        "\n",
        "We are leveraging the Impresso embedding model for embedding our input texts.\n",
        "\n",
        "üñä It's important that we apply the same embedding model to our texts and the texts in our database (which is Impresso here). Only then any similarites are meaningful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzz_VBUVfy4r"
      },
      "outputs": [],
      "source": [
        "# ---embed and search---\n",
        "\n",
        "# this is to collect the embeddings of our input texts\n",
        "embeddings = []\n",
        "# this is to collect the search results\n",
        "matches = []\n",
        "for i, part in enumerate(parts):\n",
        "    # embedding one of your documents\n",
        "    embedding = impresso_session.tools.embed_text(text=part, target=\"text\")\n",
        "    # using the embedding to search in impresso\n",
        "    matches.append(impresso_session.search.find(embedding=embedding, limit=5))\n",
        "    # storing embedding for later\n",
        "    embeddings.append(embedding)\n",
        "    print(f\"retrieved search results for text  {i+1}/{len(parts)}\")\n",
        "\n",
        "# ---some post-processing for convenience---\n",
        "\n",
        "# get ids of search results\n",
        "matches_uids = [[datum[\"uid\"] for datum in m.raw[\"data\"]] for m in matches]\n",
        "# get texts of search results\n",
        "articles = [[impresso_session.content_items.get(uid) for uid in uids] for uids in matches_uids]\n",
        "# concatenate title and text of search results\n",
        "articles = [[article.raw.get(\"title\") + \" \" + article.raw.get(\"transcript\") for article in a] for a in articles]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXSGPXxUe2uA"
      },
      "source": [
        "## üï∏Ô∏èüìä Exploring the links with Bi-partitie graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTq53q3ufGwE"
      },
      "source": [
        "### üï∏Ô∏è: **Discrete Graph**: Overview of input texts and search results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPJAg221n4AS"
      },
      "outputs": [],
      "source": [
        "from pyvis.network import Network\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Create the network\n",
        "net = Network(height=\"600px\", width=\"100%\", notebook=True, cdn_resources='in_line')\n",
        "\n",
        "# Add input nodes\n",
        "for i, text in enumerate(parts):\n",
        "    net.add_node(f\"I{i}\", label=f\"Input {i+1}\", title=text, color=\"lightblue\", size=25)\n",
        "\n",
        "# Add result nodes and edges\n",
        "for i, res_list in enumerate(articles):\n",
        "    for j, rtext in enumerate(res_list):\n",
        "        node_id = f\"R{i}_{j}\"\n",
        "        url = \"https://dev.impresso-project.ch/app/article/\" + matches_uids[i][j]\n",
        "        title = rtext + f\"<br><a href={url} target='_blank'>Link</a>\"\n",
        "        net.add_node(node_id, label=f\"R{i+1}.{j+1}\", title=title, color=\"lightgreen\")\n",
        "        net.add_edge(f\"I{i}\", node_id)\n",
        "\n",
        "# Save and embed in Colab\n",
        "net.save_graph(\"graph.html\")\n",
        "\n",
        "# Display inline in Colab\n",
        "display(HTML(\"graph.html\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmUtWjdofNrB"
      },
      "source": [
        "### üï∏Ô∏èüß† **Similarity Graph**: Revealing additional relations, and relation strengths"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Before we start**: Handy functions for mapping Impresso embeddings to vector\n",
        "\n",
        "- We need vectors to compute the similarity function\n",
        "- Impresso embeddings are encoded with a specialized string format\n",
        "- So we build and apply functions that map from the string format to an actual vector, and back"
      ],
      "metadata": {
        "id": "Evr73LiWNfLL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90thY2FMfnTG"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import struct\n",
        "\n",
        "# --- our handy mapping functions ---\n",
        "def string2vector(embedding_string):\n",
        "    # convert base64 string to a float array\n",
        "    _, arr = embedding_string.split(':')\n",
        "    arr = base64.b64decode(arr)\n",
        "    embedding_vector = [struct.unpack('f', arr[i:i+4])[0] for i in range(0, len(arr), 4)]\n",
        "    return embedding_vector\n",
        "\n",
        "# the inverse function. Not used, just for completeness sake\n",
        "def vector2string(vec, prefix=\"gte-768\"):\n",
        "    # pack floats into bytes\n",
        "    arr = b''.join(struct.pack('f', x) for x in vec)\n",
        "    # encode bytes to base64 string\n",
        "    encoded = base64.b64encode(arr).decode('utf-8')\n",
        "    # return in same format as original (\"prefix:encoded_string\")\n",
        "    return f\"{prefix}:{encoded}\"\n",
        "\n",
        "# --- applying the mapping functions ---\n",
        "# first we get the embeddings for the matches (in Impresso format, note that we already have the embedding for the input)\n",
        "matches_embeddings = [[impresso_session.content_items.get_embeddings(uid)[0] for uid in match_uid] for match_uid in matches_uids]\n",
        "# map input embedding string format to vector\n",
        "part_embeddings = [string2vector(emb) for emb in embeddings]\n",
        "# map match embedding string format to vector\n",
        "article_embeddings = [[string2vector(emb) for emb in embs] for embs in matches_embeddings]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build the similarity graph\n",
        "\n",
        "Idea:\n",
        "\n",
        "- The graph above is a *\"discrete graph\"*:\n",
        "    - It shows the matches for every input document\n",
        "- Now we would like to build a graph that is more connected:\n",
        "    - Strength of the connections\n",
        "    - Show connectivity *among the returned documents*\n",
        "- So this time we build a softer graph\n",
        "    - Captures similarity relations between any input texts,\n",
        "    - And any texts among the search results\n",
        "\n",
        "For proper display (closeness of nodes), we rely on the help of UMAP.\n",
        "- UMAP (Uniform Manifold Approximation and Projection) is a dimensionality reduction technique that projects high-dimensional data (like embeddings) into 2D or 3D space while preserving the data‚Äôs underlying structure and similarity relationships."
      ],
      "metadata": {
        "id": "LMYmTHMGN4Ui"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AEjMTtvutXI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pyvis.network import Network\n",
        "import umap\n",
        "\n",
        "# Flatten results for convenience\n",
        "flat_article_embeddings = np.vstack(article_embeddings)\n",
        "flat_articles = [r for sublist in articles for r in sublist]\n",
        "flat_uris = [None] * len(part_embeddings) + [r for sublist in matches_uids for r in sublist]\n",
        "\n",
        "# Combine everything for similarity computation\n",
        "all_embeddings = np.vstack([part_embeddings, flat_article_embeddings])\n",
        "all_texts = parts + flat_articles\n",
        "node_types = ['input'] * len(part_embeddings) + ['result'] * len(flat_article_embeddings)\n",
        "\n",
        "# Dimensionality reduction (UMAP)\n",
        "reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "coords = reducer.fit_transform(all_embeddings)\n",
        "\n",
        "# Compute cosine similarities\n",
        "sim_matrix = cosine_similarity(all_embeddings)\n",
        "\n",
        "#  Build the PyVis network\n",
        "net = Network(height=\"700px\", width=\"100%\", notebook=True, cdn_resources='in_line')\n",
        "scale = 150\n",
        "# Add nodes\n",
        "for i, (text, ntype) in enumerate(zip(all_texts, node_types)):\n",
        "    color = \"lightblue\" if ntype == \"input\" else \"lightgreen\"\n",
        "    size = 25 if ntype == \"input\" else 15\n",
        "    label = f\"I{i+1}\" if ntype == \"input\" else f\"R{i - len(flat_articles) + 1}\"\n",
        "    x, y = coords[i] * scale  # scale coordinates\n",
        "    url = None if ntype == \"input\" else \"https://dev.impresso-project.ch/app/article/\" + flat_uris[i]\n",
        "    title = text if ntype == \"input\" else text + f\"<br><a href={url} target='_blank'>Link</a>\"\n",
        "    net.add_node(\n",
        "        i,\n",
        "        label=label,\n",
        "        title=title,\n",
        "        color=color,\n",
        "        size=size,\n",
        "        x=float(x),\n",
        "        y=float(y),\n",
        "        fixed={'x': True, 'y': True}  # properly fix both axes\n",
        "    )\n",
        "\n",
        "# Add edges based on similarity\n",
        "threshold = 0.7  # Adjust to make the graph denser/sparser\n",
        "for i in range(len(all_embeddings)):\n",
        "    for j in range(i + 1, len(all_embeddings)):\n",
        "        sim = float(sim_matrix[i, j])\n",
        "        if sim > threshold:\n",
        "            net.add_edge(i, j, value=sim, title=f\"Similarity: {sim:.2f}\")\n",
        "\n",
        "\n",
        "# --- Display inline in Colab ---\n",
        "net.set_options(\"\"\"\n",
        "{\n",
        "  \"physics\": {\n",
        "    \"enabled\": false\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "net.save_graph(\"embedding_similarity_graph.html\")\n",
        "display(HTML(\"embedding_similarity_graph.html\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgL0Fj6lvDYO"
      },
      "source": [
        "## üê£ Bonuses\n",
        "\n",
        "This section is pure bonus.\n",
        "\n",
        "- We learn how to dock any of our images similarly to texts.\n",
        "- And we learn more about the text embedding model that is used in Impresso, verifying its results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Docking images\n",
        "\n",
        "What we did above with texts, also works with images. Here we take an image, and link it to impresso with similarity graph."
      ],
      "metadata": {
        "id": "L0nGreN5L9Zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining any image"
      ],
      "metadata": {
        "id": "6gUDpSWjM7RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "# picture of the notebook's author, feel free to exchange with any other image\n",
        "image_url = \"https://www.juriopitz.com/assets/img/me.png\"\n",
        "display(Image(url=image_url))"
      ],
      "metadata": {
        "id": "J81guiV6MZ5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding this image and searching similar ones in Impresso\n",
        "\n",
        "Similar to how we embedded texts, we can also embed images."
      ],
      "metadata": {
        "id": "h5ZolnEzNDI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_embedding = impresso_session.tools.embed_image(image=image_url, target=\"image\")\n",
        "matches = impresso_session.images.find(\n",
        "  embedding=img_embedding,\n",
        "  limit=4\n",
        ")"
      ],
      "metadata": {
        "id": "6Y18LKN-MT3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualizing the result as a graph\n",
        "\n",
        "Similarly to how we created the connected network of input texts nd texts in impresso, we can create the connected network of the input image and images in impresso ---- All just based on semantic similarity of embeddings"
      ],
      "metadata": {
        "id": "57l7n4KZNJ0G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBZy5--k0YHx"
      },
      "outputs": [],
      "source": [
        "# --pre-processing-- for conveinence\n",
        "matches_uids = [datum[\"uid\"] for datum in matches.raw[\"data\"]]\n",
        "links_uids = [datum[\"contentItemUid\"] for datum in matches.raw[\"data\"]]\n",
        "matches_embeddings = [impresso_session.images.get_embeddings(uid)[0] for uid in matches_uids]\n",
        "part_embeddings = [string2vector(emb) for emb in [embedding]]\n",
        "article_embeddings = [[string2vector(emb) for emb in embs] for embs in [matches_embeddings]]\n",
        "matches_uids = [matches_uids]\n",
        "links_uids = [links_uids]\n",
        "\n",
        "flat_article_embeddings = np.vstack(article_embeddings)\n",
        "flat_articles = [r for sublist in articles for r in sublist]\n",
        "flat_uris = [None] * len(part_embeddings) + [r for sublist in links_uids for r in sublist]\n",
        "\n",
        "# Combine everything for similarity computation\n",
        "all_embeddings = np.vstack([part_embeddings, flat_article_embeddings])\n",
        "all_texts = parts + flat_articles\n",
        "node_types = ['input'] * len(part_embeddings) + ['result'] * len(flat_article_embeddings)\n",
        "\n",
        "# Dimensionality reduction (UMAP)\n",
        "reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "coords = reducer.fit_transform(all_embeddings)\n",
        "\n",
        "# Compute cosine similarities\n",
        "sim_matrix = cosine_similarity(all_embeddings)\n",
        "\n",
        "#  Build the PyVis network\n",
        "net = Network(height=\"700px\", width=\"100%\", notebook=True, cdn_resources='in_line')\n",
        "scale = 150\n",
        "# Add nodes\n",
        "for i, (text, ntype) in enumerate(zip(all_texts, node_types)):\n",
        "    color = \"lightblue\" if ntype == \"input\" else \"lightgreen\"\n",
        "    size = 25 if ntype == \"input\" else 15\n",
        "    label = f\"I{i+1}\" if ntype == \"input\" else f\"R{i - len(flat_articles) + 1}\"\n",
        "    x, y = coords[i] * scale  # scale coordinates\n",
        "    url = None if ntype == \"input\" else \"https://dev.impresso-project.ch/app/article/\" + flat_uris[i]\n",
        "    title = \"Input Image\" if ntype == \"input\" else \"Impresso Image\" + f\"<br><a href={url} target='_blank'>Link</a>\"\n",
        "    net.add_node(\n",
        "        i,\n",
        "        label=label,\n",
        "        title=title,\n",
        "        color=color,\n",
        "        size=size,\n",
        "        x=float(x),\n",
        "        y=float(y),\n",
        "        fixed={'x': True, 'y': True}  # properly fix both axes\n",
        "    )\n",
        "\n",
        "# Add edges based on similarity\n",
        "threshold = 0.0  # Adjust to make the graph denser/sparser\n",
        "for i in range(len(all_embeddings)):\n",
        "    for j in range(i + 1, len(all_embeddings)):\n",
        "        sim = float(sim_matrix[i, j])\n",
        "        if sim > threshold:\n",
        "            net.add_edge(i, j, value=sim, title=f\"Similarity: {sim:.2f}\")\n",
        "\n",
        "\n",
        "# --- Display inline in Colab ---\n",
        "net.set_options(\"\"\"\n",
        "{\n",
        "  \"physics\": {\n",
        "    \"enabled\": false\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "net.save_graph(\"embedding_similarity_graph.html\")\n",
        "display(HTML(\"embedding_similarity_graph.html\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUrMNOzOvUqk"
      },
      "source": [
        "### Externally applying the Embedding Model\n",
        "\n",
        "The last cells of this notebook show how we can load an external embedding model, to embed any texts. For example, we load the same model that is currently used in Impresso. We download it from its original source and verify that it delivers the same embedding as the one in impress.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCo9qxDB5pUk"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install sentence-transformers>=3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqBqGpP2vlra"
      },
      "outputs": [],
      "source": [
        "# The first cell of revealing similarities and links can be replaced with this:\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_name_or_path=\"Alibaba-NLP/gte-multilingual-base\"\n",
        "model = SentenceTransformer(model_name_or_path, trust_remote_code=True)\n",
        "part_embeddings = model.encode(parts, normalize_embeddings=True)\n",
        "article_embeddings = [model.encode(articleset, normalize_embeddings=True) for articleset in articles]\n",
        "\n",
        "# verify that the embedding model works as intended:\n",
        "print(model.encode([\"hello\"], normalize_embeddings=True)[0][:4])\n",
        "print(string2vector(impresso_session.tools.embed_text(text=\"hello\", target=\"text\"))[:4])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
