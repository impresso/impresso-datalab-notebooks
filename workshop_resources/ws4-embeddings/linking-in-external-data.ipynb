{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/blob/main/workshop_resources/ws4-embeddings/linking-in-external-data.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "HR4045u-NGsZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbk6ClIUabUn"
      },
      "source": [
        "# UMAP visualization of text embeddings with different categories\n",
        "\n",
        "The texts are embedded via the GTE model and visualized using UMAP. Different colors represent different categories of texts, such as query texts, topic-related texts, internal documents, and external documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw-Xx3-7abUn"
      },
      "outputs": [],
      "source": [
        "!pip install pandas umap-learn matplotlib seaborn numpy mplcursors plotly 'nbformat>=4.2.0' ipykernel bokeh gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cWCzptFabUo"
      },
      "source": [
        "## The data for this use case contains the following data items\n",
        "\n",
        "- 3407 embedded impresso content items (derived via a query in impresso app (originally 5000\n",
        "  content items, but only 3407 have an embedding for now due to minimal length\n",
        "  restrictions)\n",
        "- 28 embedded external documents\n",
        "- 969 embedded impresso content items that were found by semantic search with 50 nearest\n",
        "  neighbours of 20 topic phrases:\n",
        "  `swiss banking industry;bank loans;banking secrecy;taxes on bank transactions;swiss\n",
        "bankers;geneva financial center;monetary policies;federal finances;parliamentary\n",
        "debates on banking;banking regulation;bank accounts;banks as providers;collaboration\n",
        "in banking;tax evasion;insider trading;financial crisis;gnomes of\n",
        "zurich;euromarkets;swiss bank corporation`)\n",
        "\n",
        "For convenience all embeddings are concatenated in a single bz2ipped JSONL file on\n",
        "google drive and can be downloaded by the following command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT9Rsf89abUo"
      },
      "outputs": [],
      "source": [
        "import gdown, os\n",
        "\n",
        "DATA_FILENAME = \"case_study_external_docs_linking_in.jsonl.bz2\"\n",
        "url = \"https://os.zhdk.cloud.switch.ch/impresso-public/impresso-2-ws4-lux-2025-data/linking-in-case-study/case_study_external_docs_linking_in.jsonl.bz2\"\n",
        "output = DATA_FILENAME\n",
        "os.path.exists(DATA_FILENAME) or gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bHWAI2BYx29"
      },
      "source": [
        "Some reusable code for loading the embeddings from a jsonl file.\n",
        "The data is expected to have the following fields:\n",
        "\n",
        "- \"embedding\": The text embedding as an array of numbers.\n",
        "- \"ci_id\": The unique identifier of the text. Resolvable to URLs via the Impresso webapp\n",
        "- \"category\": The category of the text. One of \"query\", \"topic**\\*\", \"internal**\\_\", \"external\\_\\_\\_\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fe1e8b2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import bz2\n",
        "\n",
        "\n",
        "def load_embeddings_from_jsonl(file_paths):\n",
        "    \"\"\"\n",
        "    Reads one or more jsonl or jsonl.bz2 files with embeddings, optional categories, and ci_id,\n",
        "    and returns a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        file_paths (list or str): A list of file paths or a single file path to the jsonl or jsonl.bz2 file(s).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with embeddings as columns, 'category' column, and 'ci_id' column.\n",
        "    \"\"\"\n",
        "    if isinstance(file_paths, str):\n",
        "        file_paths = [file_paths]\n",
        "\n",
        "    data = []\n",
        "    for file_path in file_paths:\n",
        "        if file_path.endswith(\".jsonl.bz2\"):\n",
        "            opener = bz2.open\n",
        "            mode = \"rt\"\n",
        "        elif file_path.endswith(\".jsonl\"):\n",
        "            opener = open\n",
        "            mode = \"r\"\n",
        "        else:\n",
        "            print(f\"Skipping unsupported file format: {file_path}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with opener(file_path, mode) as f:\n",
        "                for line in f:\n",
        "                    item = json.loads(line)\n",
        "                    embedding = item.get(\"embedding\")\n",
        "                    category = item.get(\n",
        "                        \"category\", \"query\"\n",
        "                    )  # Assign 'query' if no category exists\n",
        "                    ci_id = item.get(\"ci_id\")\n",
        "                    if embedding:\n",
        "                        row = dict(\n",
        "                            zip([f\"emb_{i}\" for i in range(len(embedding))], embedding)\n",
        "                        )\n",
        "                        row[\"category\"] = category\n",
        "                        row[\"ci_id\"] = ci_id\n",
        "                        data.append(row)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File not found at {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file_path}: {e}\")\n",
        "\n",
        "    # Convert list of dictionaries to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Reorder columns to have category and ci_id at the end\n",
        "    if \"category\" in df.columns:\n",
        "        category_column = df.pop(\"category\")\n",
        "        df[\"category\"] = category_column\n",
        "    if \"ci_id\" in df.columns:\n",
        "        ci_id_column = df.pop(\"ci_id\")\n",
        "        df[\"ci_id\"] = ci_id_column\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4yUvYCLY9sa"
      },
      "source": [
        "# Dimension reduction to 2D using UMAP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db098c1c"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def perform_umap_reduction(df, n_components=2, random_state=42):\n",
        "    \"\"\"\n",
        "    Applies UMAP to reduce the dimensionality of vectors in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the vectors and potentially 'category' and 'ci_id' columns.\n",
        "        n_components (int): The number of dimensions to reduce to.\n",
        "        random_state (int): Random state for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with UMAP embeddings and the 'category' and 'ci_id' columns.\n",
        "    \"\"\"\n",
        "    reducer = umap.UMAP(n_components=n_components, random_state=random_state)\n",
        "\n",
        "    # Select only the embedding columns (assuming they start with 'emb_')\n",
        "    embedding_columns = [col for col in df.columns if col.startswith(\"emb_\")]\n",
        "    vector_data = df[embedding_columns]\n",
        "\n",
        "    embedding = reducer.fit_transform(vector_data)\n",
        "    df_umap = pd.DataFrame(embedding, columns=[f\"umap_x\", f\"umap_y\"])\n",
        "\n",
        "    # Include 'category' and 'ci_id' if they exist in the original DataFrame\n",
        "    if \"category\" in df.columns:\n",
        "        df_umap[\"category\"] = df[\"category\"]\n",
        "    if \"ci_id\" in df.columns:\n",
        "        df_umap[\"ci_id\"] = df[\"ci_id\"]\n",
        "\n",
        "    return df_umap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiPnT5cZabUp"
      },
      "source": [
        "## Bokeh Visualization with Links and Simple Text Search in Category Labels for Highlighting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoEaSkcZabUp"
      },
      "outputs": [],
      "source": [
        "from bokeh.plotting import figure, output_file, save, show\n",
        "from bokeh.models import (\n",
        "    HoverTool,\n",
        "    TapTool,\n",
        "    OpenURL,\n",
        "    ColumnDataSource,\n",
        "    TextInput,\n",
        "    CustomJS,\n",
        ")\n",
        "from bokeh.transform import factor_cmap\n",
        "from bokeh.layouts import column\n",
        "\n",
        "\n",
        "def visualize_umap_bokeh(\n",
        "    df_umap,\n",
        "    title=\"UMAP Visualization with Clickable URLs\",\n",
        "    output_filename=\"umap_bokeh.html\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Creates an interactive Bokeh scatter plot where points are clickable and open URLs.\n",
        "    Includes search functionality to find and highlight points by category.\n",
        "\n",
        "    Args:\n",
        "        df_umap (pd.DataFrame): DataFrame with UMAP embeddings, 'category' column, and 'ci_id'.\n",
        "        title (str): Title of the plot.\n",
        "        output_filename (str): Name of the HTML file to save.\n",
        "\n",
        "    Returns:\n",
        "        bokeh.plotting.figure: Bokeh figure object.\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying the original dataframe\n",
        "    df_plot = df_umap.copy()\n",
        "\n",
        "    # Create URLs\n",
        "    if \"ci_id\" in df_plot.columns:\n",
        "        df_plot[\"url\"] = df_plot[\"ci_id\"].apply(\n",
        "            lambda x: (\n",
        "                f\"https://dev.impresso-project.ch/app/article/{x}\"\n",
        "                if pd.notna(x)\n",
        "                else \"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        df_plot[\"url\"] = \"\"\n",
        "\n",
        "    # Extract category prefix for coloring\n",
        "    def get_category_prefix(cat):\n",
        "        if pd.isna(cat):\n",
        "            return \"other\"\n",
        "        if \"__\" in str(cat):\n",
        "            return str(cat).split(\"__\")[0]\n",
        "        return str(cat)\n",
        "\n",
        "    df_plot[\"category_prefix\"] = df_plot[\"category\"].apply(get_category_prefix)\n",
        "\n",
        "    # Create size column - make topic dots 50% larger\n",
        "    df_plot[\"dot_size\"] = df_plot[\"category_prefix\"].apply(\n",
        "        lambda x: 12 if x == \"topics\" else 8\n",
        "    )\n",
        "\n",
        "    # Add alpha column for search highlighting (default: normal visibility)\n",
        "    df_plot[\"alpha\"] = 0.6\n",
        "\n",
        "    # Create ColumnDataSource\n",
        "    source = ColumnDataSource(df_plot)\n",
        "\n",
        "    # Get unique category prefixes for color mapping\n",
        "    category_prefixes = df_plot[\"category_prefix\"].unique().tolist()\n",
        "\n",
        "    # Create figure\n",
        "    p = figure(\n",
        "        width=1800,\n",
        "        height=1000,\n",
        "        title=title,\n",
        "        tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
        "        toolbar_location=\"above\",\n",
        "    )\n",
        "\n",
        "    # Create custom color palette for category prefixes\n",
        "    prefix_color_map = {\n",
        "        \"query\": \"#9d9c9a\",\n",
        "        \"topics\": \"#ff7f0e\",\n",
        "        \"internal\": \"#8c564b\",\n",
        "        \"external\": \"#fd0581\",\n",
        "        \"other\": \"#7f7f7f\",\n",
        "    }\n",
        "\n",
        "    # Build palette based on category prefixes in the data\n",
        "    palette = []\n",
        "    for prefix in category_prefixes:\n",
        "        if prefix in prefix_color_map:\n",
        "            palette.append(prefix_color_map[prefix])\n",
        "        else:\n",
        "            palette.append(\"#7f7f7f\")\n",
        "\n",
        "    color_mapper = factor_cmap(\n",
        "        \"category_prefix\", palette=palette, factors=category_prefixes\n",
        "    )\n",
        "\n",
        "    # Add scatter plot with alpha from data source\n",
        "    scatter = p.circle(\n",
        "        \"umap_x\",\n",
        "        \"umap_y\",\n",
        "        source=source,\n",
        "        size=\"dot_size\",\n",
        "        color=color_mapper,\n",
        "        alpha=\"alpha\",  # Use alpha from data source\n",
        "        legend_field=\"category_prefix\",\n",
        "    )\n",
        "\n",
        "    # Add hover tool with detailed information\n",
        "    hover = HoverTool(\n",
        "        tooltips=[\n",
        "            (\"Category\", \"@category\"),\n",
        "            (\"Prefix\", \"@category_prefix\"),\n",
        "            (\"CI ID\", \"@ci_id\"),\n",
        "            (\"URL\", \"@url\"),\n",
        "            (\"Coordinates\", \"(@umap_x{0.00}, @umap_y{0.00})\"),\n",
        "        ]\n",
        "    )\n",
        "    p.add_tools(hover)\n",
        "\n",
        "    # Add tap tool to open URLs when clicking on points\n",
        "    tap = TapTool()\n",
        "    p.add_tools(tap)\n",
        "\n",
        "    # Configure tap tool to open URL\n",
        "    url_open = OpenURL(url=\"@url\")\n",
        "    tap.callback = url_open\n",
        "\n",
        "    # Styling\n",
        "    p.legend.location = \"top_right\"\n",
        "    p.legend.click_policy = \"hide\"\n",
        "    p.legend.label_text_font_size = \"10pt\"\n",
        "    p.legend.title = \"Category Types\"\n",
        "    p.legend.title_text_font_size = \"11pt\"\n",
        "    p.legend.title_text_font_style = \"bold\"\n",
        "    p.legend.label_text_color = \"#333333\"\n",
        "    p.legend.border_line_width = 2\n",
        "    p.legend.border_line_color = \"#cccccc\"\n",
        "    p.legend.border_line_alpha = 0.8\n",
        "    p.legend.background_fill_alpha = 0.9\n",
        "    p.legend.spacing = 5\n",
        "    p.legend.padding = 10\n",
        "    p.xaxis.axis_label = \"UMAP X\"\n",
        "    p.yaxis.axis_label = \"UMAP Y\"\n",
        "\n",
        "    # Create search input widget\n",
        "    search_input = TextInput(\n",
        "        title=\"Search categories (case-insensitive):\",\n",
        "        placeholder=\"e.g., tax evasion, climate, etc.\",\n",
        "        width=400,\n",
        "    )\n",
        "\n",
        "    # JavaScript callback for search functionality - searches only the category part after \"__\"\n",
        "    callback = CustomJS(\n",
        "        args=dict(source=source),\n",
        "        code=\"\"\"\n",
        "        const search_term = cb_obj.value.toLowerCase().trim();\n",
        "        const data = source.data;\n",
        "        const categories = data['category'];\n",
        "        const alphas = data['alpha'];\n",
        "        const sizes = data['dot_size'];\n",
        "        const original_sizes = data['category_prefix'].map(prefix => prefix === 'topics' ? 12 : 8);\n",
        "\n",
        "        // Split search terms by space or underscore to get individual search words\n",
        "        const search_words = search_term.split(/[\\\\s_]+/).filter(word => word.length > 0);\n",
        "\n",
        "        // Reset all points\n",
        "        for (let i = 0; i < categories.length; i++) {\n",
        "            if (search_term === '') {\n",
        "                // No search term: show all normally\n",
        "                alphas[i] = 0.6;\n",
        "                sizes[i] = original_sizes[i];\n",
        "            } else {\n",
        "                // Extract the part after \"__\" (or use full category if no \"__\")\n",
        "                const category_full = categories[i].toLowerCase();\n",
        "                const category_parts = category_full.split('__');\n",
        "                const category_to_search = category_parts.length > 1 ? category_parts[1] : category_full;\n",
        "\n",
        "                // Split category into words by underscore or space\n",
        "                const category_words = category_to_search.split(/[\\\\s_]+/).filter(word => word.length > 0);\n",
        "\n",
        "                // Check if ALL search words appear in the category words\n",
        "                // Each search word must match (be contained in) at least one category word\n",
        "                let match = true;\n",
        "                for (const search_word of search_words) {\n",
        "                    let search_word_found = false;\n",
        "                    for (const cat_word of category_words) {\n",
        "                        if (cat_word.includes(search_word)) {\n",
        "                            search_word_found = true;\n",
        "                            break;\n",
        "                        }\n",
        "                    }\n",
        "                    if (!search_word_found) {\n",
        "                        match = false;\n",
        "                        break;\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                if (match) {\n",
        "                    // Highlight matching points\n",
        "                    alphas[i] = 0.8;\n",
        "                    sizes[i] = original_sizes[i] * 1.5;  // Make matching points larger\n",
        "                } else {\n",
        "                    // Dim non-matching points\n",
        "                    alphas[i] = 0.1;\n",
        "                    sizes[i] = original_sizes[i];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        source.change.emit();\n",
        "    \"\"\",\n",
        "    )\n",
        "\n",
        "    search_input.js_on_change(\"value\", callback)\n",
        "\n",
        "    # Combine search input and plot in a layout\n",
        "    layout = column(search_input, p)\n",
        "\n",
        "    # Output to HTML file\n",
        "    output_file(output_filename)\n",
        "    save(layout)\n",
        "\n",
        "    print(f\"✅ Bokeh visualization saved to: {output_filename}\")\n",
        "    print(f\"📌 Click on any point to open its URL in a new browser tab!\")\n",
        "    print(f\"🔍 Use the search box to filter points by category name!\")\n",
        "\n",
        "    return layout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i-r8NeIabUq"
      },
      "source": [
        "# Plug All Elements and run them\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCX1GSftabUq"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42\n",
        "# Different RANDOM_STATE numbers change the non-deterministic UMAP dimenions reduction\n",
        "file_list = [DATA_FILENAME]  # Using the existing file for demonstration\n",
        "\n",
        "# Load the embeddings from the files, including ci_id\n",
        "df = load_embeddings_from_jsonl(file_list)\n",
        "\n",
        "# Perform UMAP reduction\n",
        "# The perform_umap_reduction function now includes 'ci_id' in the output DataFrame\n",
        "df_umap_result = perform_umap_reduction(df, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiqp6prxabUq"
      },
      "outputs": [],
      "source": [
        "# Create and save Bokeh visualization\n",
        "bokeh_fig = visualize_umap_bokeh(\n",
        "    df_umap_result,\n",
        "    title=\"Interactive UMAP Visualization - Click points to open impresso URLs\",\n",
        "    output_filename=\"umap_bokeh_clickable_query+topics+internal+external+search.html\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCZ2allPabUq"
      },
      "source": [
        "Open Bokeh HTML file [`umap_bokeh_clickable_query+topics+internal+external+search.html`](umap_bokeh_clickable_query+topics+internal+external+search.html) in\n",
        "your browser. In colab you find it under Files tabs and can be downloaded. When you run the notebook locally, the link should work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdWFTUuYabUq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
