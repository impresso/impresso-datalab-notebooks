# Impresso Datalab reviewer's guidelines

The Impresso Datalab editorial pipeline is guided by FAIR principles and strives to produce robust and quality materials. Therefore, we implement a transparent open peer-review process. Reviewers add their feedback to GitHub issues dedicated to each Jupyter Notebook. This helps the community understand how decisions are made and how our materials are produced. 

**As a reviewer, please me mindful that your feedback is published openly.**

## Internal review (Impresso):
1. Is the code consistent? Eg. Use of variables, formatting
2. Is the explanation of the code correct? Is there imprecise information? Could we expand it in some aspect you consider important to understand the code?
3. Are there any references to external resources that could enrich this notebook?
4. Is the information (text in markdown) contained in the NB enough to perform the proposed task? Is there something missing?
5. Do the objectives under 'what you will learn' match the content? Do we provide everything we promise in the objectives?

## External review:
1. Is it clear for you what the objective of this NB is?
2. Is it easy to identify whether this NB is relevant to you?
3. Is the NB written in a clear format/layout? Do the sections/titles make sense to you?
4. Is the information provided enough for you to understand the code?
5. Is there anything you would like further explanation (Eg. any unclear concept)?
6. Are you able to run every cell in the NB and understand its outputs using your own examples?
7. Can you imagine any use of this NB in your own research pipelines? What would make this notebook more relevant for your research and/or teaching?
