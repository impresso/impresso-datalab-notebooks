{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhQe5f0yBLS5"
      },
      "source": [
        "# OCR Quality Assessment with `impresso-pipelines` Package\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/blob/main/annotate/ocrqa_pipeline_demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oEACNWrBUFc"
      },
      "source": [
        "### What is this notebook about?\n",
        "\n",
        "This notebook demonstrates how to use the Impresso OCR Quality Assessment (ocrqa) pipeline to evaluate the quality of text recognition. It provides a simple example and an overview of advanced usage options.\n",
        "\n",
        "#### Why is this useful?\n",
        "\n",
        "- OCR (Optical Character Recognition) quality can vary significantly across different archives, historical fonts, time periods, and OCR systems.\n",
        "- A quality score helps you quickly assess text readability, filter out low-quality texts, and compare OCR results from different sources.\n",
        "\n",
        "#### How it works\n",
        "\n",
        "The tool assigns a score between 0 and 1 based on sets of unique words, not individual word occurrences:\n",
        "\n",
        "- 1.0 = Perfect quality (all words are recognized)\n",
        "- 0.0 = Very poor quality (no words are recognized)\n",
        "- Example: A score of 0.8 means 80% of unique words were recognized.\n",
        "\n",
        "#### Technical background\n",
        "\n",
        "- The `ocrqa` tool relies on lists of known words for each supported language.\n",
        "- These word lists are compiled from sources such as Wikipedia articles and [Wortschatz Leipzig](https://wortschatz.uni-leipzig.de/en/download) sentences.\n",
        "- The word lists are stored efficiently using \"Bloom filters\", which allow for fast and memory-efficient membership testing.\n",
        "- The tool supports multiple languages (e.g., German, French, English), each with its\n",
        "  own separate word list. However, frequent foreign words might be included in the list\n",
        "  as well, according to their appearance in the source texts (e.g. Wikipedia articles).\n",
        "- If the language of an input text is not specified, the tool uses Impresso's language identification tool to determine the language automatically.\n",
        "- If a language is not supported, the tool will notify you accordingly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eQJBze2Mc_Q"
      },
      "source": [
        "## What will you learn?\n",
        "\n",
        "In this notebook, you will:\n",
        "\n",
        "- Understand the functionality of the `ocrqa` subpackage from the Impresso Pipelines package.\n",
        "- Learn how to calculate a **QA score** for a given raw text.\n",
        "- Discover how the pipeline **automatically detects language** using impresso [`langident`](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/langident_pipeline_demo.ipynb) before applying QA scoring.\n",
        "- Explore different use cases, including **basic and advanced usage** of the OCR QA pipeline.\n",
        "- Recognize some limitations of the pipeline, such as handling **uncommon words and short texts**.\n",
        "\n",
        "By the end of this notebook, you will have a clear understanding of how the OCR QA score is computed and its practical applications.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyx4fqlXBXEX"
      },
      "source": [
        "---\n",
        "\n",
        "## Prerequisites\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q891fk9XFHay"
      },
      "source": [
        "First, you should install Impresso package:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2_e-lIOFMRN",
        "outputId": "90a83a00-c021-432e-97ae-11910e0b4bb1"
      },
      "outputs": [],
      "source": [
        "%pip install impresso_pipelines[ocrqa]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-tdR7o4Mky7"
      },
      "source": [
        "---\n",
        "\n",
        "## Workflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHEncypABbeo"
      },
      "source": [
        "### Basic Usage\n",
        "\n",
        "Start by importing the necessary module from Impresso Pipelines package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVi5bRsaFdLO"
      },
      "outputs": [],
      "source": [
        "from impresso_pipelines.ocrqa import OCRQAPipeline\n",
        "\n",
        "ocrqa_pipeline = OCRQAPipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9NbNk_THMER"
      },
      "source": [
        "Once you initialize the pipeline, you can simply provide the text you'd like to classify. This example demonstrates the use of German text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycZz3bjwHEPg"
      },
      "outputs": [],
      "source": [
        "de_text = \"Ein kleiner Hund wqeg Max lebte in einem ruhigen Dorf.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DebXqYB0HRtM",
        "outputId": "921c42a9-f410-4e5b-97df-bc039ccc1a42"
      },
      "outputs": [],
      "source": [
        "ocrqa_pipeline(de_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlmUZvxIHaVk"
      },
      "source": [
        "If no language is explicitly specified, the OCR QA pipeline uses the Impresso\n",
        "`langident` pipeline to automatically detect the language of the text. For more details\n",
        "on the `langident` pipeline, please refer to the [langident\n",
        "pipeline demo notebook](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/langident_pipeline_demo.ipynb).\n",
        "\n",
        "Once the language is detected, the pipeline checks if a corresponding Bloom filter exists. The default output of the pipeline is a dictionary containing the detected language and the corresponding QA score. The computed QA score is a rough measure and is intentionally rounded to one decimal place to account for minor variations, such as the presence of unusual names or OCR errors, which should not significantly impact the overall score.\n",
        "\n",
        "In this example, the score is **0.9**, meaning that approximately **one out of ten words** does not exist in the Bloom filter. This suggests that while the OCR process was largely successful, there was a small misidentification (_wqeg_) in the text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT0z6ugxBdF6"
      },
      "source": [
        "### Advanced Usage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6iu4jelILoK"
      },
      "source": [
        "This pipeline offers several additional attributes that can be used when calling it to gain a deeper understanding of the results. These attributes include `language`, `version`, `diagnostics`, `model_id`, and `supported_languages`:\n",
        "\n",
        "- `language`: Accepts language abbreviation strings such as \"en\" (English) or \"de\" (German). If provided, the pipeline assumes the specified language and skips the language detection step, directly using the corresponding Bloom filter.\n",
        "\n",
        "- `version`: Accepts a specific Bloom filter model version in the format \"1.0.5\" or \"1.0.6\". If specified, the pipeline uses the requested version (if available) and skips the automatic retrieval of the latest model.\n",
        "\n",
        "- `diagnostics`: Boolean. If set to True, the pipeline returns additional information, such as known_tokens, unknown_tokens, and the Bloom filter name used. For more details, see the sections below.\n",
        "\n",
        "- `model_id`: Boolean. If set to True, the pipeline includes the name of the Bloom filter model used in the output.\n",
        "\n",
        "- `supported_languages`: Boolean. If set to True, the pipeline returns a list of supported languages (i.e., languages for which a Bloom filter is available).\n",
        "\n",
        "These attributes can be used individually, in combination with each other, or all at once, depending on the level of detail needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qpBHjqvLMS2"
      },
      "source": [
        "**Example 1**: `language`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9jmh60QA8Xx",
        "outputId": "7fd25f88-706b-4d86-fce5-ef35e98b6881"
      },
      "outputs": [],
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, language=\"lb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6IfMkZpLpFD"
      },
      "source": [
        "Even though the provided text is clearly in German, specifying the language as Luxembourgish, for example, forces the pipeline to use the corresponding Bloom filter for that language. If the selected language is unsupported, the pipeline will return an appropriate error message.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BCop6krMBkS"
      },
      "source": [
        "**Example 2**: `version`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_y6HMbrLS-c",
        "outputId": "137f2873-ada4-4d1b-95da-5d0504b04dbc"
      },
      "outputs": [],
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, version=\"1.0.5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIzkhKNqM8uP"
      },
      "source": [
        "In the example above, by explicitly setting the `version` to _1.0.5_ , you are instructing the pipeline to use the Bloom filter corresponding to this version, even if a more recent version is available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuHr1YDHNZGF"
      },
      "source": [
        "**Example 3**: `diagnostics`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOSWx-rkMpvJ",
        "outputId": "d22c7ead-2f76-4c4e-c281-e4b578cf4eac"
      },
      "outputs": [],
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, diagnostics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcbLziN_OwfA"
      },
      "source": [
        "Once you set `diagnostics` to _True_ , an additional key, `diagnostics`, will be added to the dictionary. The value of this key contains all known and unknown tokens, as well as the name of the Bloom filter used. In this example, we can see that there are no unknown words, meaning every word exists in this specific Bloom filter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAGVU8cGNfy-"
      },
      "source": [
        "**Example 4**: `model_id`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FHAOX0QPati",
        "outputId": "ffd641cf-8e58-43b2-fa0c-22fd1e2aa9ab"
      },
      "outputs": [],
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, model_id=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzEnDhokPeeB"
      },
      "source": [
        "Similar to the `diagnostics` attribute, the `model_id` attribute is a simpler version. If set to `True`, the pipeline will return an additional key, `bloom_filter`, with the value indicating the Bloom filter that was used for the analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3X0rNIeNgON"
      },
      "source": [
        "**Example 5**: `supported languages`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7jkZAR2NlnF",
        "outputId": "5a4279c5-1aec-4662-bae1-daf2ba76f300"
      },
      "outputs": [],
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(de_text, supported_languages=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xHzczRtP9_t"
      },
      "source": [
        "Once `supported_languages` is set to _True_, the pipeline returns an additional key, `supported_languages`, with a value containing a list of all currently supported languages (i.e., languages that have a corresponding Bloom filter).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YLZAibuP1Jn"
      },
      "source": [
        "**Example 6**: All at once\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKLHCUZ4P3OG",
        "outputId": "1d35954a-8121-4d7b-c2bd-4cf11cc3aa11"
      },
      "outputs": [],
      "source": [
        "# Using the same German text example as before\n",
        "ocrqa_pipeline(\n",
        "    de_text,\n",
        "    language=\"fr\",\n",
        "    version=\"1.0.5\",\n",
        "    diagnostics=True,\n",
        "    model_id=True,\n",
        "    supported_languages=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoA2pr-XQgMd"
      },
      "source": [
        "You can use a mix of additional parameters, or all of them at once, to gain a deeper understanding of your QA score. In the example above, we set the language to French, which results in many unknown tokens being identified, as the Bloom filter used may not cover certain French words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He5YuZ_nR350"
      },
      "source": [
        "### Limitations of the OCR QA Score Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvSzfgE2Qcvp"
      },
      "outputs": [],
      "source": [
        "short_de_text_with_unusual_name = \"Glebs geht ins Büro.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-V1gu0MSHLG",
        "outputId": "e03d20d8-69c8-4ad0-ade7-8a1f633bb0c1"
      },
      "outputs": [],
      "source": [
        "# Example 1: Very short sentence\n",
        "ocrqa_pipeline(short_de_text_with_unusual_name, diagnostics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvq7ue67TWq_"
      },
      "source": [
        "As shown, the language detection model struggles with **short texts**, leading to potential misclassification. Additionally, **uncommon names** or **rare words** can lower the QA score, even if they were correctly identified by OCR. This happens because these words do not exist in the current version of the Bloom filter, making them appear as unknown tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au7M3ra8Mx_S"
      },
      "source": [
        "---\n",
        "\n",
        "## Conclusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2donc9ZM4hI"
      },
      "source": [
        "### Summary\n",
        "\n",
        "In this notebook, we've explored the OCR QA Pipeline from the Impresso package, which evaluates OCR quality by calculating a score between 0 and 1. The pipeline:\n",
        "\n",
        "- Automatically detects text language using [`langident`](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/langident_pipeline_demo.ipynb) (or accepts manual language specification)\n",
        "- Uses Bloom filters to identify known/unknown words and calculate a quality score\n",
        "- Offers additional parameters for customization (`language`, `version`, `diagnostics`, `model_id`, `supported_languages`)\n",
        "- Has limitations with short texts and uncommon words\n",
        "- Provides a standardized approach to OCR quality assessment across multiple languages\n",
        "\n",
        "The pipeline is particularly useful for evaluating OCR quality in historical documents and identifying potential errors in digitized text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_YxOk_rSTWq"
      },
      "source": [
        "### Next steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq_RTRtAM6Du"
      },
      "source": [
        "Since this subpackage relies on the Impresso langident subpackage, you might be interested in exploring the [demo notebook](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/langident_pipeline_demo.ipynb) for langident.\n",
        "\n",
        "Additionally, you can find the repository for the [**Impresso Pipelines package**](https://github.com/impresso/impresso-pipelines/tree/mallet_pipeline).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4DQgojRPyXn"
      },
      "source": [
        "---\n",
        "## Project and License info\n",
        "\n",
        "### Impresso project\n",
        "\n",
        "[Impresso - Media Monitoring of the Past](https://impresso-project.ch) is an interdisciplinary research project that aims to develop and consolidate tools for processing and exploring large collections of media archives across modalities, time, languages and national borders. The first project (2017-2021) was funded by the Swiss National Science Foundation under grant No. [CRSII5_173719](http://p3.snf.ch/project-173719) and the second project (2023-2027) by the SNSF under grant No. [CRSII5_213585](https://data.snf.ch/grants/grant/213585) and the Luxembourg National Research Fund under grant No. 17498891.\n",
        "\n",
        "### Copyright\n",
        "\n",
        "Copyright (C) 2024 The Impresso team.\n",
        "\n",
        "### License\n",
        "\n",
        "This program is provided as open source under the [GNU Affero General Public License](https://github.com/impresso/impresso-pyindexation/blob/master/LICENSE) v3 or later.\n",
        "\n",
        "---\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/impresso/impresso.github.io/blob/master/assets/images/3x1--Yellow-Impresso-Black-on-White--transparent.png?raw=true\" width=\"350\" alt=\"Impresso Project Logo\"/>\n",
        "</p>\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
