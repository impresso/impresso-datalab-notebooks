{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhQe5f0yBLS5"
   },
   "source": [
    "# OCR Quality Assessment with impresso-pipelines Package\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/blob/main/annotate/ocrqa_pipeline_demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oEACNWrBUFc"
   },
   "source": [
    "## What is this notebook about?\n",
    "\n",
    "This notebook introduces the OCRQA component of the [impresso-pipelines](https://pypi.org/project/impresso-pipelines/) Python package. The broader goal of the impresso pipelines is to make the internal data processing workflows of the impresso project reusable and accessible to others. It allows external users—such as researchers, developers, or digital humanities practitioners—to apply the same processing steps we used on our historical newspaper collections to their own text collections.\n",
    "\n",
    "The package is designed to minimize the coding effort required. By offering ready-to-use pipelines, users can adopt impresso approach to document processing with minimal configuration. This ensures consistency, comparability, and transparency in how OCR-derived data is prepared and evaluated.\n",
    "\n",
    "In this notebook, we focus on the [ocrqa](https://github.com/impresso/impresso-pipelines/tree/main/impresso_pipelines/ocrqa) subpackage, which enables quality assessment of OCR outputs. You will learn how to apply the OCRQA pipeline to your text data, explore different usage options, and interpret the results.\n",
    "\n",
    "## Why is this useful?\n",
    "\n",
    "- OCR (Optical Character Recognition) quality can vary significantly across different archives, historical fonts, time periods, and OCR systems.\n",
    "- A quality score helps you quickly assess text readability, filter out low-quality texts, and compare OCR results from different sources.\n",
    "\n",
    "## How it works\n",
    "\n",
    "The tool assigns a score between 0 and 1 based on sets of unique words, not individual word occurrences:\n",
    "\n",
    "- 1.0 = Perfect or near perfect quality (all or **almost all words** are recognized - 0.95 to 1.0)\n",
    "- 0.0 = Very poor quality (no words or **almost no words** are recognized)\n",
    "- Example: A score of 0.8 means **roughly** 80% of unique words were recognized.\n",
    "\n",
    "## Technical background\n",
    "\n",
    "- The `ocrqa` tool relies on lists of known words for each supported language.\n",
    "- These word lists are compiled from sources such as Wikipedia articles and [Wortschatz Leipzig](https://wortschatz.uni-leipzig.de/en/download) sentences.\n",
    "- The word lists are stored efficiently using \"Bloom filters\", which allow for fast and memory-efficient membership testing.\n",
    "- The tool supports multiple languages (e.g., German, French, English), each with its\n",
    "  own separate word list. However, frequent foreign words might be included in the list\n",
    "  as well, according to their appearance in the source texts (e.g. Wikipedia articles).\n",
    "- If the language of an input text is not specified, the tool uses Impresso's language identification tool to determine the language automatically.\n",
    "- If a language is not supported, the tool will notify you accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eQJBze2Mc_Q"
   },
   "source": [
    "## What will you learn?\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "- Understand the functionality of the `ocrqa` subpackage from the Impresso Pipelines package.\n",
    "- Learn how to calculate a **QA score** for a given raw text.\n",
    "- Discover how the pipeline **automatically detects language** using impresso [`langident`](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/langident_pipeline_demo.ipynb) before applying QA scoring.\n",
    "- Explore different use cases, including **basic and advanced usage** of the OCR QA pipeline.\n",
    "- Recognize some limitations of the pipeline, such as handling **uncommon words and short texts**.\n",
    "\n",
    "By the end of this notebook, you will have a clear understanding of how the OCR QA score is computed and its practical applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful resources\n",
    "- For technical details on this library, please refer to the repository of the [Impresso Pipelines package](https://github.com/impresso/impresso-pipelines/tree/main).\n",
    "- This Programming Historian tutorial on [Generating an Ordered Data Set from an OCR Text File](https://programminghistorian.org/en/lessons/generating-an-ordered-data-set-from-an-OCR-text-file) provides guidance on how to produce metadata from raw OCR output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyx4fqlXBXEX"
   },
   "source": [
    "## Prerequisites\n",
    "First, start by installing `impresso-pipelines` package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2_e-lIOFMRN"
   },
   "outputs": [],
   "source": [
    "%pip install \"impresso_pipelines[ocrqa]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you continue, please, restart the kernel to apply changes.** To do so, on Google Colab, go to *Runtime* and select *Restart session*. Then, you can continue from the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHEncypABbeo"
   },
   "source": [
    "## Basic Usage\n",
    "\n",
    "Start by importing the necessary module from `impresso-pipelines` package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVi5bRsaFdLO"
   },
   "outputs": [],
   "source": [
    "from impresso_pipelines.ocrqa import OCRQAPipeline\n",
    "\n",
    "ocrqa_pipeline = OCRQAPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9NbNk_THMER"
   },
   "source": [
    "Once you initialize the pipeline, you can simply provide the text you'd like to classify. This example demonstrates the use of German text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycZz3bjwHEPg"
   },
   "outputs": [],
   "source": [
    "de_text = \"Ein kleiner Hund wqeg Max lebte in einem ruhigen Dorf.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DebXqYB0HRtM"
   },
   "outputs": [],
   "source": [
    "ocrqa_pipeline(de_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlmUZvxIHaVk"
   },
   "source": [
    "If no language is explicitly specified, the OCR QA pipeline uses the Impresso\n",
    "`langident` pipeline to automatically detect the language of the text. For more details\n",
    "on the `langident` pipeline, please refer to the [langident\n",
    "pipeline demo notebook](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/langident_pipeline_demo.ipynb).\n",
    "\n",
    "Once the language is detected, the pipeline checks if a corresponding Bloom filter exists. The default output of the pipeline is a dictionary containing the detected language and the corresponding QA score. The computed QA score is a rough measure and is intentionally rounded to one decimal place to account for minor variations, such as the presence of unusual names or OCR errors, which should not significantly impact the overall score.\n",
    "\n",
    "In this example, the score is **0.9**, meaning that approximately **one out of ten words** does not exist in the Bloom filter. This suggests that while the OCR process was largely successful, there was a small misidentification (_wqeg_) in the text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LT0z6ugxBdF6"
   },
   "source": [
    "## Advanced Usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6iu4jelILoK"
   },
   "source": [
    "This pipeline offers several additional attributes that can be used when calling it to gain a deeper understanding of the results. These attributes include `language`, `version`, `diagnostics`, `model_id`, and `supported_languages`:\n",
    "\n",
    "- `language`: Accepts language abbreviation strings such as \"en\" (English) or \"de\" (German). If provided, the pipeline assumes the specified language and skips the language detection step, directly using the corresponding Bloom filter.\n",
    "\n",
    "- `version`: Accepts a specific Bloom filter model version in the format \"1.0.5\" or \"1.0.6\". If specified, the pipeline uses the requested version (if available) and skips the automatic retrieval of the latest model.\n",
    "\n",
    "- `diagnostics`: Boolean. If set to True, the pipeline returns additional information, such as known_tokens, unknown_tokens, and the Bloom filter name used. For more details, see the sections below.\n",
    "\n",
    "- `model_id`: Boolean. If set to True, the pipeline includes the name of the Bloom filter model used in the output.\n",
    "\n",
    "- `supported_languages`: Boolean. If set to True, the pipeline returns a list of supported languages (i.e., languages for which a Bloom filter is available).\n",
    "\n",
    "These attributes can be used individually, in combination with each other, or all at once, depending on the level of detail needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qpBHjqvLMS2"
   },
   "source": [
    "**Example 1**: `language`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9jmh60QA8Xx"
   },
   "outputs": [],
   "source": [
    "# Using the same German text example as before\n",
    "ocrqa_pipeline(de_text, language=\"lb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6IfMkZpLpFD"
   },
   "source": [
    "Even though the provided text is clearly in German, specifying the language as Luxembourgish, for example, forces the pipeline to use the corresponding Bloom filter for that language. If the selected language is unsupported, the pipeline will return an appropriate error message.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BCop6krMBkS"
   },
   "source": [
    "**Example 2**: `version`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_y6HMbrLS-c"
   },
   "outputs": [],
   "source": [
    "# Using the same German text example as before\n",
    "ocrqa_pipeline(de_text, version=\"1.0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIzkhKNqM8uP"
   },
   "source": [
    "In the example above, by explicitly setting the `version` to _1.0.5_ , you are instructing the pipeline to use the Bloom filter corresponding to this version, even if a more recent version is available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuHr1YDHNZGF"
   },
   "source": [
    "**Example 3**: `diagnostics`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOSWx-rkMpvJ"
   },
   "outputs": [],
   "source": [
    "# Using the same German text example as before\n",
    "ocrqa_pipeline(de_text, diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcbLziN_OwfA"
   },
   "source": [
    "Once you set `diagnostics` to _True_ , an additional key, `diagnostics`, will be added to the dictionary. The value of this key contains all known and unknown tokens, as well as the name of the Bloom filter used. In this example, we can see that there are no unknown words, meaning every word exists in this specific Bloom filter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAGVU8cGNfy-"
   },
   "source": [
    "**Example 4**: `model_id`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FHAOX0QPati"
   },
   "outputs": [],
   "source": [
    "# Using the same German text example as before\n",
    "ocrqa_pipeline(de_text, model_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzEnDhokPeeB"
   },
   "source": [
    "Similar to the `diagnostics` attribute, the `model_id` attribute is a simpler version. If set to `True`, the pipeline will return an additional key, `bloom_filter`, with the value indicating the Bloom filter that was used for the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3X0rNIeNgON"
   },
   "source": [
    "**Example 5**: `supported languages`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7jkZAR2NlnF"
   },
   "outputs": [],
   "source": [
    "# Using the same German text example as before\n",
    "ocrqa_pipeline(de_text, supported_languages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xHzczRtP9_t"
   },
   "source": [
    "Once `supported_languages` is set to _True_, the pipeline returns an additional key, `supported_languages`, with a value containing a list of all currently supported languages (i.e., languages that have a corresponding Bloom filter).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YLZAibuP1Jn"
   },
   "source": [
    "**Example 6**: All at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKLHCUZ4P3OG"
   },
   "outputs": [],
   "source": [
    "# Using the same German text example as before\n",
    "ocrqa_pipeline(\n",
    "    de_text,\n",
    "    language=\"fr\",\n",
    "    version=\"1.0.5\",\n",
    "    diagnostics=True,\n",
    "    model_id=True,\n",
    "    supported_languages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoA2pr-XQgMd"
   },
   "source": [
    "You can use a mix of additional parameters, or all of them at once, to gain a deeper understanding of your QA score. In the example above, we set the language to French, which results in many unknown tokens being identified, as the Bloom filter used may not cover certain French words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "He5YuZ_nR350"
   },
   "source": [
    "## Limitations of the OCR QA Score Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvSzfgE2Qcvp"
   },
   "outputs": [],
   "source": [
    "short_de_text_with_unusual_name = \"Glebs geht ins Büro.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-V1gu0MSHLG"
   },
   "outputs": [],
   "source": [
    "# Example 1: Very short sentence\n",
    "ocrqa_pipeline(short_de_text_with_unusual_name, diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvq7ue67TWq_"
   },
   "source": [
    "As shown, the language detection model struggles with **short texts**, leading to potential misclassification. Additionally, **uncommon names** or **rare words** can lower the QA score, even if they were correctly identified by OCR. This happens because these words do not exist in the current version of the Bloom filter, making them appear as unknown tokens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2donc9ZM4hI"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored the OCR QA Pipeline from the Impresso package, which evaluates OCR quality by calculating a score between 0 and 1. The pipeline:\n",
    "\n",
    "- Automatically detects text language using [`langident`](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/langident_pipeline_demo.ipynb) (or accepts manual language specification)\n",
    "- Uses Bloom filters to identify known/unknown words and calculate a quality score\n",
    "- Offers additional parameters for customization (`language`, `version`, `diagnostics`, `model_id`, `supported_languages`)\n",
    "- Has limitations with short texts and uncommon words\n",
    "- Provides a standardized approach to OCR quality assessment across multiple languages\n",
    "\n",
    "The pipeline is particularly useful for evaluating OCR quality in historical documents and identifying potential errors in digitized text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_YxOk_rSTWq"
   },
   "source": [
    "## Next steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq_RTRtAM6Du"
   },
   "source": [
    "Since this subpackage relies on the Impresso langident subpackage, you might be interested in exploring the [demo notebook](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/langident_pipeline_demo.ipynb) for langident.\n",
    "\n",
    "Additionally, you can find more technical details in the repository of the [Impresso Pipelines package](https://github.com/impresso/impresso-pipelines/tree/mallet_pipeline).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4DQgojRPyXn"
   },
   "source": [
    "---\n",
    "## Project and License info\n",
    "\n",
    "### Notebook credits [![CreditLogo.png](data:image/png;base64,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)](https://credit.niso.org/)\n",
    "**Writing - Original draft:** Glebs Vinarskis. **Conceptualization:** Simon Clematide, Glebs Vinarskis. **Software:** Simon Clematide, Juri Opitz, Andrianos Michail. **Writing - Review & Editing:** Caio Mello. **Validation:** Estelle Bunout. **Datalab editorial board:** Caio Mello (Managing), Pauline Conti, Emanuela Boros, Marten Düring, Juri Opitz, Martin Grandjean, Estelle Bunout. **Data curation & Formal analysis:** Maud Ehrmann, Emanuela Boros, Pauline Conti, Simon Clematide, Juri Opitz, Andrianos Michail. **Methodology:** Simon Clematide, Glebs Vinarskis. **Supervision:** Simon Clematide. **Funding aquisition:** Maud Ehrmann, Simon Clematide, Marten Düring, Raphaëlle Ruppen Coutaz.\n",
    "\n",
    "<br><a target=\"_blank\" href=\"https://creativecommons.org/licenses/by/4.0/\">\n",
    "  <img src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by.png\"  width=\"100\" alt=\"Open In Colab\"/>\n",
    "</a> \n",
    "\n",
    "This notebook is published under [CC BY 4.0 License](https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "For feedback on this notebook, please send an email to info@impresso-project.ch\n",
    "\n",
    "### Impresso project\n",
    "\n",
    "[Impresso - Media Monitoring of the Past](https://impresso-project.ch) is an interdisciplinary research project that aims to develop and consolidate tools for processing and exploring large collections of media archives across modalities, time, languages and national borders. The first project (2017-2021) was funded by the Swiss National Science Foundation under grant No. [CRSII5_173719](http://p3.snf.ch/project-173719) and the second project (2023-2027) by the SNSF under grant No. [CRSII5_213585](https://data.snf.ch/grants/grant/213585) and the Luxembourg National Research Fund under grant No. 17498891.\n",
    "<br></br>\n",
    "### License\n",
    "\n",
    "All Impresso code is published open source under the [GNU Affero General Public License](https://github.com/impresso/impresso-pyindexation/blob/master/LICENSE) v3 or later.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/impresso/impresso.github.io/blob/master/assets/images/3x1--Yellow-Impresso-Black-on-White--transparent.png?raw=true\" width=\"350\" alt=\"Impresso Project Logo\"/>\n",
    "</p>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
