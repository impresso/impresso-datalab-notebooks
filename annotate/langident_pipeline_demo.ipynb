{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlxKbkly00q4"
      },
      "source": [
        "# Language Identification with *impresso-pipelines* Package\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/blob/main/annotate/langident_pipeline_demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dBRT6Lg0_3X"
      },
      "source": [
        "## What is this notebook about?\n",
        "This notebook introduces the language identification component of the\n",
        "[impresso-pipelines](https://pypi.org/project/impresso-pipelines/) Python package. The broader goal of impresso pipelines is to make\n",
        "the internal data processing workflows of the impresso project reusable and accessible\n",
        "to others. It allows external users—such as researchers, developers, or digital\n",
        "humanities practitioners—to apply the same processing steps we used on our historical\n",
        "newspaper collections to their own text collections.\n",
        "\n",
        "The package is designed to require as little coding effort as possible. By offering ready-to-use pipelines, users can replicate impresso’s approach to document processing with minimal configuration. This ensures consistency, comparability, and transparency in how text data is prepared and analyzed.\n",
        "\n",
        "In this particular notebook, we focus on the langident subpackage, which performs\n",
        "automatic language detection (currently supports German, French, Luxembourgish and Italian). You will learn how to apply language identification to\n",
        "your multilingual document collection and explore tools for understanding and diagnosing the\n",
        "results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## What will you learn?\n",
        "\n",
        "In this notebook, you will:\n",
        "\n",
        "- Understand how to use the `langident` subpackage from the impresso Pipelines package for language detection.\n",
        "\n",
        "- Learn how to classify text into different languages using a simple pipeline.\n",
        "\n",
        "- Explore diagnostic features to analyze language predictions.\n",
        "\n",
        "- Identify common challenges in language detection, such as handling short texts or\n",
        "  ambiguous words.\n",
        "\n",
        "- Experiment with multilingual and edge-case scenarios to observe model behavior.\n",
        "\n",
        "This hands-on guide will provide you with practical insights into language identification and its limitations. ​\n",
        "\n",
        "## Useful resources\n",
        "\n",
        "- For technical details on this library, please refer to the repository of the [Impresso Pipelines package](https://github.com/impresso/impresso-pipelines/tree/main).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI_rST2p1-4Y"
      },
      "source": [
        "\n",
        "## Prerequisites\n",
        "\n",
        "First, start by installing `impresso-pipelines` package. Please, note that it might require you to restart kernel to apply changes. To do so, on Google Colab, go to *Runtime* and select *Restart session*. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QctlGqvC0KuO"
      },
      "outputs": [],
      "source": [
        "%pip install -q impresso_pipelines[langident]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_Uik0Sd70C7"
      },
      "source": [
        "## Basic usage\n",
        "\n",
        "Start by importing the necessary module from `impresso-pipelines` package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtitCAr93Apc"
      },
      "outputs": [],
      "source": [
        "from impresso_pipelines.langident import LangIdentPipeline\n",
        "\n",
        "lang_pipeline = LangIdentPipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oui-HWvY3ZBi"
      },
      "source": [
        "Once you initialize the pipeline, you can simply provide the text you'd like to classify. This example demonstrates the use of German text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtQ3v9c33NI7"
      },
      "outputs": [],
      "source": [
        "de_text = \"Ein kleiner Hund namens Max lebte in einem ruhigen Dorf.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tko-ibcv3zJy"
      },
      "outputs": [],
      "source": [
        "lang_pipeline(de_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKhiiYDR4DHH"
      },
      "source": [
        "The default output of the pipeline is a dictionary containing the top predicted language and its corresponding score (expressed as a probability). The score is rounded to three decimal places for better readability. Please note that the probabilities for all supported languages add up to 1 (by default, only the top language is returned).\n",
        "\n",
        "As shown, the pipeline uses the language identification model to correctly classify this text as German, with a rounded probability of 100%.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOTaGXLI65Bg"
      },
      "source": [
        "## Advanced usage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNYo2bvQ_c1G"
      },
      "source": [
        "When using the pipeline with text, you can additionally specify two parameters: `diagnostics` and `model_id`.\n",
        "\n",
        "- `diagnostics`: A boolean value. If set to True, it returns not only the top predicted language but also all languages that the model can detect, along with their corresponding scores.\n",
        "\n",
        "- `model_id`: A boolean value. If set to True, it returns the name of the model used to identify the language of the text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-1eYVtbAMoA"
      },
      "source": [
        "Here we skip the part of module importing and initialization as it was done above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzgB6bEW66qD"
      },
      "outputs": [],
      "source": [
        "# Using text example from before\n",
        "lang_pipeline(de_text, diagnostics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx_4AeK-CO56"
      },
      "source": [
        "As shown, it returns a `language_dict` containing a list of all supported languages and their corresponding scores. Since the text is purely in German, all other scores are 0.0.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5BQ5tbfDd61"
      },
      "source": [
        "Below is an example of using `model_id` with and without `diagnostics`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxkhiBmBDIYV"
      },
      "outputs": [],
      "source": [
        "lang_pipeline(de_text, model_id=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI6HUfC4DsA8"
      },
      "outputs": [],
      "source": [
        "lang_pipeline(de_text, model_id=True, diagnostics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiToPyATDzdU"
      },
      "source": [
        "In both cases, we can see an additional key, `model_id`, which stores the name of the language identification model used by the pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTIBgZY6C3Od"
      },
      "source": [
        "## Mixed language example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRnC8oXuC8kg"
      },
      "outputs": [],
      "source": [
        "mixed_text = (\n",
        "    \"Max marchait doucement. Der vento soffiait fort, aber la strada restait vide.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j59q6T_JDEKT"
      },
      "outputs": [],
      "source": [
        "lang_pipeline(mixed_text, diagnostics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O128P703DKcv"
      },
      "source": [
        "As shown, this time the model clearly detects some French and even Italian, but French remains the top predicted language, with German as the second most likely.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DB6YPK16mkT"
      },
      "source": [
        "## Advanced Pipeline Initialization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ToYPc3H4kk7"
      },
      "source": [
        "By default, the pipeline automatically selects the most recent language identification model from the Impresso HF repository: `impresso-project/impresso-floret-langident`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8akaEac67WX"
      },
      "source": [
        "However, the module initialization allows you to pass additional arguments to use a specific model instead of the default one. These arguments include `model_id`, `repo_id`, and `revision`.\n",
        "\n",
        "- `model_id`: Specifies the name of the model.\n",
        "- `repo_id`: Specifies the repository where the model is located.\n",
        "\n",
        "- `revision`: Specifies the branch name of the repository.\n",
        "\n",
        "By providing all three, you can force the pipeline to use the language model you have specified.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRdWbmfd6TH5"
      },
      "outputs": [],
      "source": [
        "from impresso_pipelines.langident import (\n",
        "    LangIdentPipeline,\n",
        ")  # There's no need to import the module again if it has already been imported\n",
        "\n",
        "lang_pipeline = LangIdentPipeline(\n",
        "    model_id=\"langident-v1.0.0.bin\",\n",
        "    repo_id=\"impresso-project/impresso-floret-langident\",\n",
        "    revision=\"main\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VILeEY1e9EU3"
      },
      "outputs": [],
      "source": [
        "# Using text example from before\n",
        "lang_pipeline(de_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbqtvL7h9PwF"
      },
      "source": [
        "Once again, we see the same pipeline output as before.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9bnUx-JE9l3"
      },
      "source": [
        "## Common Pitfalls in Language Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22Bs7eSrFA_I"
      },
      "outputs": [],
      "source": [
        "short_fr_text = \"Je mange.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI5kI--oGIuU"
      },
      "outputs": [],
      "source": [
        "short_de_text = \"Der Computer auf dem Tisch funktioniert gut.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Goc7TiWLGm4h"
      },
      "outputs": [],
      "source": [
        "short_de_text_with_unusual_name = \"Gleb geht ins Büro.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDtaVKXlFl-K"
      },
      "outputs": [],
      "source": [
        "# Example 1: Very short sentence\n",
        "lang_pipeline(short_fr_text, diagnostics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qhlLkM6Fo8W"
      },
      "outputs": [],
      "source": [
        "# Exaple 2: Not language specific sentence\n",
        "lang_pipeline(short_de_text, diagnostics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKnCcz7IGqME"
      },
      "outputs": [],
      "source": [
        "# Example 3: Short sentence and unsual name\n",
        "lang_pipeline(short_de_text_with_unusual_name, diagnostics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2T9zzzoGM8t"
      },
      "source": [
        "As demonstrated, this pipeline struggles to accurately detect the language when the text is too short. This challenge becomes even more pronounced when the words used are not strongly tied to a specific language. Additionally, the model encounters difficulties with short sentences that contain uncommon names. In general, the longer the text sample, the higher the detection accuracy.\n",
        "\n",
        "As shown above, despite low confidence scores, the pipeline correctly predicts the language in the first two cases (a short French text and a non-language-specific German text). However, in the third example — where the sentence is both short and includes an unusual, non-German name — the model makes an incorrect prediction.\n",
        "\n",
        "This example highlights the importance of longer, more language-distinctive sentences for achieving higher accuracy and confidence in language classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P94qtVFCVGm"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook provides a step-by-step guide on using the `langident` subpackage from the Impresso Python package for language detection. It begins with an introduction to the package and instructions on installing the necessary dependencies.\n",
        "\n",
        "The workflow section covers:\n",
        "\n",
        "- Basic Usage: Initializing the language identification pipeline and classifying single-language texts.\n",
        "- Advanced Usage: Exploring additional pipeline features, such as retrieving full probability distributions for multiple languages.\n",
        "- Handling Challenging Cases: Analyzing model limitations when dealing with short or ambiguous texts, multilingual content, and names that may not be strongly language-specific.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95dJGhS4CVzA"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "You might also be interested in a follow-up notebook on [OCR Quality Assessment with impresso-pipelines Package](https://github.com/impresso/impresso-datalab-notebooks/tree/main/annotate/ocrqa_pipeline_demo.ipynb), which utilizes the `langident` language detection.\n",
        "\n",
        "Additionally, you can find more technical details in the repository of the [Impresso Pipelines package](https://github.com/impresso/impresso-pipelines/tree/main).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcRKDomECJv7"
      },
      "source": [
        "---\n",
        "## Project and License info\n",
        "\n",
        "### Notebook credits [![CreditLogo.png](data:image/png;base64,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)](https://credit.niso.org/)\n",
        "\n",
        "INSERT CREDITS HERE\n",
        "<br></br>\n",
        "This notebook is published under [CC BY 4.0 License](https://creativecommons.org/licenses/by/4.0/)\n",
        "<br><a target=\"_blank\" href=\"https://creativecommons.org/licenses/by/4.0/\">\n",
        "  <img src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by.png\"  width=\"100\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<br></br>\n",
        "\n",
        "### Impresso project\n",
        "\n",
        "[Impresso - Media Monitoring of the Past](https://impresso-project.ch) is an interdisciplinary research project that aims to develop and consolidate tools for processing and exploring large collections of media archives across modalities, time, languages and national borders. The first project (2017-2021) was funded by the Swiss National Science Foundation under grant No. [CRSII5_173719](http://p3.snf.ch/project-173719) and the second project (2023-2027) by the SNSF under grant No. [CRSII5_213585](https://data.snf.ch/grants/grant/213585) and the Luxembourg National Research Fund under grant No. 17498891.\n",
        "<br></br>\n",
        "### License\n",
        "\n",
        "All Impresso code is published open source under the [GNU Affero General Public License](https://github.com/impresso/impresso-pyindexation/blob/master/LICENSE) v3 or later.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/impresso/impresso.github.io/blob/master/assets/images/3x1--Yellow-Impresso-Black-on-White--transparent.png?raw=true\" width=\"350\" alt=\"Impresso Project Logo\"/>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
